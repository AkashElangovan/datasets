# Datasets Generated using Nemotron-4-340B-Instruct

Welcome to the repository for datasets generated using Nemotron-4-340B-Instruct, along with datasets scraped from open-source datasets on Hugging Face and manually handcrafted high-quality datasets.

## About Nemotron-4-340B-Instruct

Nemotron-4-340B-Instruct is a large language model (LLM) fine-tuned from the Nemotron-4-340B-Base model. It has been optimized for English-based single and multi-turn chat use-cases and supports a context length of 4,096 tokens. This model is utilized as part of a synthetic data generation pipeline to create high-quality training data, which can help researchers and developers build their own LLMs.

## Datasets

This repository contains various datasets generated through different methods:

1. **Synthetic Data using Nemotron-4-340B-Instruct**: 
    - Generated using Nemotron-4-340B-Instruct, which creates synthetic data for training and evaluating language models.
    
2. **Open-Source Datasets from Hugging Face**: 
    - Curated by scraping open-source datasets available on Hugging Face, ensuring a diverse collection of data.
    
3. **Handcrafted High-Quality Datasets**: 
    - Manually created to ensure high quality and relevance for specific tasks and applications.

other dataesets will be updated soon
